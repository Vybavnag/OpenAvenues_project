{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch Layer Results:\n",
      "Product IDs: [2702277, 14700042, 1004875, 1201504, 26202882]\n",
      "Trending Percentages: [-0.3333333333333333, 1.0, 1.0, 1.0, 1.0]\n",
      "Speed Layer Results:\n",
      "Similar Product Recommendations for User 532647354: [2601036, 100004742, 16700606, 1005003, 1004403]\n",
      "Precomputed results stored.\n",
      "Serving Layer Results:\n",
      "Stored Results: [(2702277, -0.3333333333333333), (14700042, 1.0), (1004875, 1.0), (1201504, 1.0), (26202882, 1.0)]\n",
      "Product with the Highest Trending Percentage: 14700042\n",
      "Most Similar Product from Speed Layer: 2601036\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import datetime\n",
    "import threading\n",
    "import time\n",
    "from queue import Queue\n",
    "from collections import defaultdict\n",
    "\n",
    "class Message:\n",
    "    def __init__(self, timestamp: int, userId: str, type: str, product_Id: str, brand: str, category: str):\n",
    "        self.timestamp = timestamp\n",
    "        self.userId = userId\n",
    "        self.type = type\n",
    "        self.product_Id = product_Id\n",
    "        self.brand = brand\n",
    "        self.category = category\n",
    "\n",
    "    def __str__(self):\n",
    "        return f\"Message:\\n\\tUser Id: {self.userId}\\n\\tAt Timestamp: {self.timestamp}\\n\\tType: {self.type}\\n\\tProduct Id: {self.product_Id}\\n\\tBrand: {self.brand}\\n\\tCategory: {self.category}\"\n",
    "\n",
    "class KafkaBroker:\n",
    "    def __init__(self):\n",
    "        self.message_queues = {}\n",
    "\n",
    "    def produce_message(self, message: Message, topic: str) -> None:\n",
    "        if topic not in self.message_queues:\n",
    "            self.message_queues[topic] = Queue()\n",
    "        self.message_queues[topic].put(message)\n",
    "\n",
    "    def consume_messages(self):\n",
    "        while True:\n",
    "            messages_exist = False\n",
    "            for index, message_queue in self.message_queues.items():\n",
    "                if not message_queue.empty():\n",
    "                    messages_exist = True\n",
    "                    yield message_queue.get()\n",
    "            if not messages_exist:\n",
    "                time.sleep(0.01)\n",
    "                continue\n",
    "            yield None  # Yield None when there are no more messages to consume\n",
    "\n",
    "class KafkaProducer:\n",
    "    def __init__(self, broker: KafkaBroker, topic: str, data: pd.DataFrame, name: str):\n",
    "        self.broker = broker\n",
    "        self.topic = topic\n",
    "        self.data = data\n",
    "        self.thread = None\n",
    "        self.name = name  # Add the 'name' attribute\n",
    "\n",
    "    def start(self):\n",
    "        self.thread = threading.Thread(target=self.produce_messages)\n",
    "        self.thread.start()\n",
    "\n",
    "    def send(self, message: Message):\n",
    "        #print(f\"Sending message from {self.name}: {message}\")\n",
    "        self.broker.produce_message(message, self.topic)\n",
    "\n",
    "    def produce_messages(self):\n",
    "        df = self.data.sample(10000)\n",
    "\n",
    "        for _, row in df.iterrows():\n",
    "            timestamp = int(pd.Timestamp(row['event_time']).timestamp())\n",
    "            user_id = str(row['user_id'])\n",
    "            event_type = str(row['event_type'])\n",
    "            product_id = row['product_id']\n",
    "            brand = row['brand']\n",
    "            category = row['category_code']\n",
    "            message = Message(timestamp, user_id, event_type, product_id, brand, category)\n",
    "            self.send(message)\n",
    "            time.sleep(0.001)\n",
    "        time.sleep(1)\n",
    "\n",
    "class KafkaConsumer:\n",
    "    def __init__(self, broker: KafkaBroker, topic: str, layer_type: str, name: str):\n",
    "        self.broker = broker\n",
    "        self.topic = topic\n",
    "        self.queue = Queue()\n",
    "        self.thread = None\n",
    "        self.layer_type = layer_type\n",
    "        self.name = name  # Add the 'name' attribute\n",
    "\n",
    "    def start(self):\n",
    "        self.thread = threading.Thread(target=self.run)\n",
    "        self.thread.start()\n",
    "\n",
    "    def run(self):\n",
    "        for message in self.broker.consume_messages():\n",
    "            if message is not None:\n",
    "                #print(f\"{self.layer_type} Layer {self.name} received message: {message}\")\n",
    "                self.queue.put(message)\n",
    "\n",
    "    def poll(self, timeout=1):\n",
    "        try:\n",
    "            return self.queue.get(timeout=timeout)\n",
    "        except:\n",
    "            return None\n",
    "\n",
    "class BatchLayer:\n",
    "    def __init__(self, start_date, end_date):\n",
    "        self.popularity = {}\n",
    "        self.buckets = {}\n",
    "        self.user_interactions = defaultdict(set)\n",
    "        self.start_date = start_date\n",
    "        self.end_date = end_date\n",
    "\n",
    "    def precompute_trending(self, min_change_threshold=10):\n",
    "        trending_items = {}\n",
    "        if len(self.buckets) >= 2:\n",
    "            for bucket in range(len(self.buckets) - 1):\n",
    "                current_bucket = self.buckets.get(bucket, {})\n",
    "                next_bucket = self.buckets.get(bucket + 1, {})\n",
    "                trending_items[bucket] = {\n",
    "                    product: ((next_bucket.get(product, 0) - current_bucket.get(product, 0)) / max(current_bucket.get(product, 0) + next_bucket.get(product, 0), 1))\n",
    "                    for product in set(list(current_bucket.keys()) + list(next_bucket.keys()))\n",
    "                    if current_bucket.get(product, 0) > 0 and abs((next_bucket.get(product, 0) - current_bucket.get(product, 0))) >= min_change_threshold\n",
    "                }\n",
    "\n",
    "            trending_flat = {}\n",
    "            for items in trending_items.values():\n",
    "                trending_flat.update(items)\n",
    "\n",
    "            top_trending_items = dict(sorted(trending_flat.items(), key=lambda item: item[1], reverse=True)[:5])\n",
    "            product_ids = list(top_trending_items.keys())\n",
    "            trending_percentages = list(top_trending_items.values())\n",
    "\n",
    "            # Ensure trending percentages are positive\n",
    "            trending_percentages = [percentage if percentage < -1 else -1 * percentage for percentage in trending_percentages]\n",
    "\n",
    "            return product_ids, trending_percentages\n",
    "        else:\n",
    "            print(\"Insufficient data to compute trending.\")\n",
    "            return [], []\n",
    "\n",
    "    def process_realtime_event(self, message):\n",
    "        event_time = pd.to_datetime(message.timestamp, unit='s')\n",
    "        event_type = message.type\n",
    "        product_id = message.product_Id\n",
    "        user_id = message.userId\n",
    "\n",
    "        if event_type in ['view', 'cart']:\n",
    "            self.user_interactions[user_id].add(product_id)\n",
    "\n",
    "        if event_type not in ['view', 'cart']:\n",
    "            if self.start_date <= event_time.date() <= self.end_date:\n",
    "                # Update popularity count for the product\n",
    "                self.popularity[product_id] = self.popularity.get(product_id, 0) + 1\n",
    "\n",
    "                # Update popularity for each product in the current bucket\n",
    "                bucket_start = (event_time.date() - self.start_date).days // 7\n",
    "                self.buckets.setdefault(bucket_start, {})\n",
    "                for prod_id in self.popularity:\n",
    "                    self.buckets[bucket_start][prod_id] = self.popularity[prod_id]\n",
    "\n",
    "class SpeedLayer:\n",
    "    def __init__(self, max_interactions=5):\n",
    "        self.max_interactions = max_interactions\n",
    "        self.user_interactions = defaultdict(list)\n",
    "\n",
    "    def process_realtime_event(self, message):\n",
    "        product_id = message.product_Id\n",
    "        brand = message.brand\n",
    "        category = message.category\n",
    "\n",
    "        user_id = message.userId\n",
    "        if user_id not in self.user_interactions:\n",
    "            self.user_interactions[user_id] = [(product_id, brand, category)]\n",
    "        else:\n",
    "            self.user_interactions[user_id].append((product_id, brand, category))\n",
    "            if len(self.user_interactions[user_id]) > self.max_interactions:\n",
    "                self.user_interactions[user_id] = self.user_interactions[user_id][-self.max_interactions:]\n",
    "\n",
    "    def find_similar_products(self, user_id, num_similar=5):\n",
    "        user_interactions = self.user_interactions.get(user_id, [])\n",
    "        similar_products = defaultdict(float)\n",
    "        for u_id, interactions in self.user_interactions.items():\n",
    "            if u_id != user_id:\n",
    "                common_interactions = len(set(interactions).intersection(user_interactions))\n",
    "                similarity_score = common_interactions / (len(user_interactions) + len(interactions) - common_interactions)\n",
    "                for interaction in interactions:\n",
    "                    product_id, brand, category = interaction\n",
    "                    similar_products[product_id] += similarity_score\n",
    "\n",
    "        similar_products = dict(sorted(similar_products.items(), key=lambda item: item[1], reverse=True))\n",
    "        return list(similar_products.keys())[:num_similar]\n",
    "\n",
    "class ServingLayer:\n",
    "    def __init__(self):\n",
    "        self.precomputed_results = []\n",
    "\n",
    "    def store_precomputed_results(self, product_ids, trending_percentages):\n",
    "        self.precomputed_results = list(zip(product_ids, trending_percentages))\n",
    "        print(\"Precomputed results stored.\")\n",
    "\n",
    "    def __str__(self):\n",
    "        return str(self.precomputed_results)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    data = pd.read_csv('2019-Nov.csv')\n",
    "    broker = KafkaBroker()\n",
    "    consumer_batch = KafkaConsumer(broker, 'user_activities', layer_type='Batch', name='Consumer Batch')\n",
    "    consumer_speed = KafkaConsumer(broker, 'user_activities', layer_type='Speed', name='Consumer Speed')\n",
    "    producer = KafkaProducer(broker, 'user_activities', data, name='Producer')\n",
    "\n",
    "    producer.start()\n",
    "    consumer_batch.start()\n",
    "    consumer_speed.start()\n",
    "\n",
    "    batch_layer = BatchLayer(start_date=datetime.date(2019, 11, 1), end_date=datetime.date(2019, 11, 30))\n",
    "    speed_layer = SpeedLayer()\n",
    "\n",
    "    timeout_seconds = 20\n",
    "    consumed_messages = 0\n",
    "    start_time = time.time()\n",
    "\n",
    "    while True:\n",
    "        message_batch = consumer_batch.poll()\n",
    "        message_speed = consumer_speed.poll()\n",
    "\n",
    "        if message_batch:\n",
    "            consumed_messages += 1\n",
    "            #print(f\"[#{consumed_messages}] {consumer_batch.name} received: {message_batch}\")\n",
    "            batch_layer.process_realtime_event(message_batch)\n",
    "        if message_speed:\n",
    "            consumed_messages += 1\n",
    "            #print(f\"[#{consumed_messages}] {consumer_speed.name} received: {message_speed}\")\n",
    "            speed_layer.process_realtime_event(message_speed)\n",
    "\n",
    "        if not message_batch and not message_speed and time.time() - start_time >= timeout_seconds:\n",
    "            break\n",
    "\n",
    "        time.sleep(0.01)\n",
    "\n",
    "\n",
    "\n",
    "    print(\"Batch Layer Results:\")\n",
    "    min_change_threshold = 1\n",
    "    product_ids, trending_percentages = batch_layer.precompute_trending(min_change_threshold)\n",
    "    print(\"Product IDs:\", product_ids)\n",
    "    print(\"Trending Percentages:\", trending_percentages)\n",
    "\n",
    "    print(\"Speed Layer Results:\")\n",
    "    user_id = '532647354'\n",
    "    similar_products = speed_layer.find_similar_products(user_id, num_similar=5)\n",
    "    print(\"Similar Product Recommendations for User {}: {}\".format(user_id, similar_products))\n",
    "\n",
    "    serving_layer = ServingLayer()\n",
    "\n",
    "    serving_layer.store_precomputed_results(product_ids, trending_percentages)\n",
    "\n",
    "    print(\"Serving Layer Results:\")\n",
    "    stored_results = serving_layer.__str__()\n",
    "    print(\"Stored Results:\", stored_results)\n",
    "\n",
    "    # Extracting the product with the highest trending percentage\n",
    "    highest_trending_product = None\n",
    "    highest_trending_percentage = 0\n",
    "    for product_id, trending_percentage in zip(product_ids, trending_percentages):\n",
    "        if trending_percentage > highest_trending_percentage:\n",
    "            highest_trending_product = product_id\n",
    "            highest_trending_percentage = trending_percentage\n",
    "    print(\"Product with the Highest Trending Percentage:\", highest_trending_product)\n",
    "\n",
    "    # Extracting the most similar product from the speed layer\n",
    "    most_similar_product = similar_products[0]\n",
    "    print(\"Most Similar Product from Speed Layer:\", most_similar_product)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Display results to the user\n",
    "#Batch Layer and speed Layer emit scores for products based on what was the most trending \n",
    "#print out which class name recives messages "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://github.com/avbatchelor/trail-conditions\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
